# Intro
* [Lessons from archives: strategies for collecting sociocultural data in machine learning](https://dl.acm.org/doi/abs/10.1145/3351095.3372829)
* Bode, Katherine (Forthcoming 2020): Why You Canâ€™t Model Away Bias, Modern Language Quarterly 81.1. preprint: katherinebode.files.wordpress.com/2019/08/mlq2019_preprintbode_why.pdf [letzter Zugriff 27. September 2019].
# Detecting Bias
* Buolamwini, Joy, und Timnit Gebru (2018): Gender shades: Intersectional accuracy disparities in commercial gender classification. Conference on fairness, accountability and transparency.
* Caliskan, Aylin, Joanna J. Bryson und Arvind Narayanan. (2017): Semantics derived automatically from language corpora contain human-like biases. Science 356.
* Garg, Nikhil, Londa Schiebinger, Dan Jurafsky und James Zou (2018): Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences.
* May, Chandler, Alex Wang, Shikha Bordia, Samuel R. Bowman und Rachel Rudinger (2019): On Measuring Social Biases in Sentence Encoders. Conference of the NAACL.
* Sap, Maarten, Dallas Card, Saadia Gabriel, Yejin Choi und Noah A. Smith (2019): The Risk of Racial Bias in Hate Speech Detection. Conference of the ACL.
* Swinger, Nathaniel, Maria De-Arteaga, Neil Heffernan IV, Mark Leiserson und Adam Kalai (2019): What are the biases in my word embedding?. Conference on Artificial Intelligence, Ethics, and Society (AIES).
## Bias definitions
* [The Meaning and Measurement of Bias](https://azjacobs.com/measurement)
* http://web.engr.oregonstate.edu/~burnett/CS507/algorithmicBias-cacm2016.pdf
# Mitigating Bias
* [Reducing sentiment polarity for demographic attributes in word embeddings using adversarial learning](https://dl.acm.org/doi/abs/10.1145/3351095.3372837)
* Bolukbasi, Tolga, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, und Adam T Kalai (2016): Man is to computer programmer as woman is to homemaker? debiasing word embeddings. Conference of NIPS.
* Gonen, H. und Yoav Goldberg (2019): Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them. Conference of the NAACL.
* Zhang, B. H., Lemoine, B., und Mitchell, M. (2018): Mitigating unwanted biases with adversarial learning. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society.
* Zhao, J., Wang, T., Yatskar, M., Ordonez, V., und Chang, K. W. (2018): Gender bias in coreference resolution: Evaluation and debiasing methods. arXiv preprint arXiv:1804.06876.
# 1800
# Social Media

# Data
* Davidson, Thomas, Debasmita Bhattacharya und Ingmar Weber (2019): Racial Bias in Hate Speech and Abusive Language Detection Datasets. arXiv preprint arXiv:1905.12516.
* racial or sexist labelled tweets https://github.com/zeerakw/hatespeech
* sentiment tweets german https://www.spinningbytes.com/resources/germansentiment/
